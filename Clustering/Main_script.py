# -*- coding: utf-8 -*-
"""Clustering Machine Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U5yWe_kBcEz6TQAi7mI3AR9QS2IsoJfk
"""

#Konstantinos Pasvantis
#Applied Informatics
#email: aid23005@uom.edu.gr
#AM: aid23005

"""# MAIN SCRIPT"""

from keras.datasets import fashion_mnist
from keras.datasets import mnist
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn import cluster, datasets, metrics
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, UpSampling2D, Activation
import matplotlib.pyplot as plt
from keras import backend as K
from sklearn import cluster
def performance_score(input_values, cluster_indexes):
    try:
        silh_score = metrics.silhouette_score(input_values.reshape(-1,1), cluster_indexes)
        print(' .. Silhouette Coefficient score is {:.2f}'.format(silh_score))
        #print( ' ... -1: incorrect, 0: overlapping, +1: highly dense clusts.')
    except:
        print(' .. Warning: could not calculate Silhouette Coefficient score.')
        silh_score = -999

    try:
        ch_score =\
         metrics.calinski_harabasz_score(input_values.reshape(-1,1), cluster_indexes)
        print(' .. Calinski-Harabasz Index score is {:.2f}'.format(ch_score))
        #print(' ... Higher the value better the clusters.')
    except:
        print(' .. Warning: could not calculate Calinski-Harabasz Index score.')
        ch_score = -999

    try:
        db_score = metrics.davies_bouldin_score(input_values.reshape(-1,1), cluster_indexes)
        print(' .. Davies-Bouldin Index score is {:.2f}'.format(db_score))
        #print(' ... 0: Lowest possible value, good partitioning.')
    except:
        print(' .. Warning: could not calculate Davies-Bouldin Index score.')
        db_score = -999

    try:
      v_score =metrics.v_measure_score(input_values, cluster_indexes)
      print(' .. V measure score is {:.2f}'.format(v_score))
      #print(' ... Score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling.')
    except:
      print(' .. Warning: could not calculate V score.')
      v_score = -999

    return silh_score, ch_score, db_score, v_score
#import the dataset, normalise it and then split the train set into train and validation
(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()
X_train=X_train/255.0
X_test=X_test/255.0
X_train, X_valid, y_train, y_valid=train_test_split(X_train, y_train, test_size=0.15, random_state=1)

#Have a look at shapes of our splitted dataset
print(X_train.shape)
print(X_test.shape)
print(X_valid.shape)
#Here we define the cnn that compress and restores images of the train dataset
model = Sequential()
model.add(Conv2D(128, kernel_size=3, padding='same',activation='relu', input_shape=(28,28,1)))
model.add(MaxPool2D((2,2), padding='same'))
model.add(Dropout(0.2))
model.add(Conv2D(56, kernel_size=3, padding='same', activation='relu'))

model.add(MaxPool2D((2,2), padding='same'))
model.add(Dropout(0.2))

model.add(Conv2D(14, kernel_size=3, padding='same', activation='relu'))
model.add(UpSampling2D((2,2)))
model.add(Dropout(0.2))
model.add(Conv2D(128, kernel_size=3, padding='same', activation='relu'))
model.add(UpSampling2D((2,2)))
model.add(Dropout(0.2))
model.add(Conv2D(1, kernel_size=3, padding='same', activation='relu'))

model.compile(optimizer='adam', loss="mse")
model.summary()

#train the model
model.fit(X_train, X_train, epochs=10, batch_size=64,\
          validation_data=(X_valid, X_valid), verbose=1)

#exctract the encoder block
encoder = K.function([model.layers[0].input],[model.layers[6].output])

#convert images to projected data
test_encoded_images = encoder([X_test])[0].reshape(-1,7*7*14)

from google.colab import files
restored_testing_dataset = model.predict(X_test)
# Observe the reconstructed image quality
plt.figure(figsize=(20,5))
for i in range(10):
    index = y_test.tolist().index(i)
    plt.subplot(2, 10, i+1)
    plt.title('Original Image')
    plt.imshow(X_test[index].reshape((28,28)))
    plt.gray()
    plt.subplot(2, 10, i+11)
    plt.title('Restored Image')
    plt.imshow(restored_testing_dataset[index].reshape((28,28)))
    plt.gray()

plt.savefig("Original and restored images.png")
files.download("Original and restored images.png")

#comparing the metric scores for clustering using mini batch k-means
for numOfClust in range (3,11):
  print('Currently testing', str(numOfClust),\
        'number of clusters')
  mbkm = cluster.MiniBatchKMeans(n_clusters = numOfClust,random_state=1)
  mbkm.fit(test_encoded_images)
  clusterLabels = mbkm.labels_
  silh_score, ch_score, db_score, hg_score = \
  performance_score(y_test, clusterLabels)

#use minibatch kmeans with 3 clusters
# Cluster the training set
mbkm = cluster.MiniBatchKMeans(n_clusters = 3,random_state=1)
mbkm.fit(test_encoded_images)
clusterLabels = mbkm.labels_

#Visualizations for clustering using 4 clusters
fig = plt.figure(figsize=(20,20))
for clusterIdx in range(3):
    # cluster = cm[r].argmax()
    for c, val in enumerate(X_test[clusterLabels == clusterIdx][0:10]):
        fig.add_subplot(10, 10, 10*clusterIdx+c+1)
        plt.imshow(val.reshape((28,28)))
        plt.gray()
        plt.xticks([])
        plt.yticks([])
        plt.ylabel('class: '+str(clusterIdx))
plt.savefig("Clustering results using k-means.png")
files.download("Clustering results using k-means.png")

#comparing the metric scores for clustering using spectral clustering
for numOfClust in range (3,11):
  print('Currently testing', str(numOfClust),\
        'number of clusters')
  spec_clust= cluster.SpectralClustering(n_clusters=numOfClust,random_state=1)
  spec_clust.fit(test_encoded_images)
  clusterLabels = spec_clust.labels_
  # silh_score = metrics.silhouette_score(outputData.reshape(-1, 1), clusterLabels)
  silh_score, ch_score, db_score,hg_score = \
  performance_score(y_test, clusterLabels)

# Cluster the training set
spec_clust= cluster.SpectralClustering(n_clusters =7,random_state=1)
spec_clust.fit(test_encoded_images)
clusterLabels = spec_clust.labels_

#performance scores & visualizations for spectral clustering using 3 clusters
fig = plt.figure(figsize=(20,20))
for clusterIdx in range(7):
    # cluster = cm[r].argmax()
    for c, val in enumerate(X_test[clusterLabels == clusterIdx][0:10]):
        fig.add_subplot(10, 10, 10*clusterIdx+c+1)
        plt.imshow(val.reshape((28,28)))
        plt.gray()
        plt.xticks([])
        plt.yticks([])
        plt.ylabel('class: '+str(clusterIdx))
plt.savefig("Clustering results using spectral clustering.png")
files.download("Clustering results using spectral clustering.png")

#use projections to cluster the images (agglomeration)
for numOfClust in range (3,11):
  print('Currently testing', str(numOfClust),\
        'number of clusters')
  agg_clust= cluster.AgglomerativeClustering(n_clusters=numOfClust)
  agg_clust.fit(test_encoded_images)
  clusterLabels = agg_clust.labels_
  # silh_score = metrics.silhouette_score(outputData.reshape(-1, 1), clusterLabels)
  silh_score, ch_score, db_score, v_score = \
  performance_score(y_test, clusterLabels)

# Cluster the training set
agg_clust= cluster.AgglomerativeClustering(n_clusters = 3)
agg_clust.fit(test_encoded_images)
clusterLabels = agg_clust.labels_

#performance scores & visualizations
fig = plt.figure(figsize=(20,20))
for clusterIdx in range(3):
    # cluster = cm[r].argmax()
    for c, val in enumerate(X_test[clusterLabels == clusterIdx][0:10]):
        fig.add_subplot(10, 10, 10*clusterIdx+c+1)
        plt.imshow(val.reshape((28,28)))
        plt.gray()
        plt.xticks([])
        plt.yticks([])
        plt.ylabel('class: '+str(clusterIdx))
plt.savefig("Clustering results using agglomerative clustering.png")
files.download("Clustering results using agglomerative clustering.png")

#Normalised pictures without encoder
(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()
X_train=X_train/255.0
X_test=X_test/255.0
X_train, X_valid, y_train, y_valid=train_test_split(X_train, y_train, test_size=0.15, random_state=1)

X_test=X_test.reshape(-1,X_test.shape[1]*X_test.shape[2])
#comparing the metric scores for clustering using mini batch k-means (normalised in [0,1])
for numOfClust in range (3,11):
  print('Currently testing', str(numOfClust),\
        'number of clusters')
  mbkm = cluster.MiniBatchKMeans(n_clusters = numOfClust,random_state=1)
  mbkm.fit(X_test)
  clusterLabels = mbkm.labels_
  silh_score, ch_score, db_score, hg_score = \
  performance_score(y_test, clusterLabels)

#use minibatch kmeans with 3 clusters
# Cluster the training set
mbkm = cluster.MiniBatchKMeans(n_clusters = 3,random_state=1)
mbkm.fit(X_test)
clusterLabels = mbkm.labels_

#Visualizations for clustering using 3 clusters (without encoder) 
fig = plt.figure(figsize=(20,20))
for clusterIdx in range(3):
    # cluster = cm[r].argmax()
    for c, val in enumerate(X_test[clusterLabels == clusterIdx][0:10]):
        fig.add_subplot(10, 10, 10*clusterIdx+c+1)
        plt.imshow(val.reshape((28,28)))
        plt.gray()
        plt.xticks([])
        plt.yticks([])
        plt.ylabel('class: '+str(clusterIdx))
plt.savefig("Clustering results using k-means without encoder.png")
files.download("Clustering results using k-means without encoder.png")

#Normalised pictures without encoder
(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()
X_train=X_train/255.0
X_test=X_test/255.0
X_train, X_valid, y_train, y_valid=train_test_split(X_train, y_train, test_size=0.15, random_state=1)

X_test=X_test.reshape(-1,X_test.shape[1]*X_test.shape[2])
#comparing the metric scores for clustering using spectral clustering (normalised in [0,1])
for numOfClust in range (3,11):
  print('Currently testing', str(numOfClust),\
        'number of clusters')
  spec_clust= cluster.SpectralClustering(n_clusters=numOfClust,random_state=1)
  spec_clust.fit(X_test)
  clusterLabels = spec_clust.labels_
  silh_score, ch_score, db_score, hg_score = \
  performance_score(y_test, clusterLabels)

#Normalised pictures without encoder
(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()
X_train=X_train/255.0
X_test=X_test/255.0
X_train, X_valid, y_train, y_valid=train_test_split(X_train, y_train, test_size=0.15, random_state=1)

X_test=X_test.reshape(-1,X_test.shape[1]*X_test.shape[2])
#use projections to cluster the images (agglomeration)
for numOfClust in range (3,11):
  print('Currently testing', str(numOfClust),\
        'number of clusters')
  agg_clust= cluster.AgglomerativeClustering(n_clusters=numOfClust)
  agg_clust.fit(X_test)
  clusterLabels = agg_clust.labels_
  # silh_score = metrics.silhouette_score(outputData.reshape(-1, 1), clusterLabels)
  silh_score, ch_score, db_score, v_score = \
  performance_score(y_test, clusterLabels)

#use aglomerative with 3 clusters
# Cluster the training set
mbkm = cluster.MiniBatchKMeans(n_clusters = 3,random_state=1)
mbkm.fit(X_test)
clusterLabels = mbkm.labels_

#performance scores & visualizations
fig = plt.figure(figsize=(20,20))
for clusterIdx in range(3):
    # cluster = cm[r].argmax()
    for c, val in enumerate(X_test[clusterLabels == clusterIdx][0:10]):
        fig.add_subplot(10, 10, 10*clusterIdx+c+1)
        plt.imshow(val.reshape((28,28)))
        plt.gray()
        plt.xticks([])
        plt.yticks([])
        plt.ylabel('class: '+str(clusterIdx))
plt.savefig("Clustering results using agglomerative clustering without encoder.png")
files.download("Clustering results using agglomerative clustering without encoder.png")